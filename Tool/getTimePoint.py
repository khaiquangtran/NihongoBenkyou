from google.cloud.texttospeech_v1beta1 import VoiceSelectionParams, AudioConfig, AudioEncoding, SynthesizeSpeechRequest, SynthesisInput, TextToSpeechClient
import os

# Set biáº¿n mÃ´i trÆ°á»ng Ä‘á»ƒ dÃ¹ng credentials (tá»« file JSON táº£i tá»« Google Cloud)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "H:/13_Tai_lieu/virtual.json"  # ğŸ” thay Ä‘Æ°á»ng dáº«n nÃ y

def synthesize():
    client = TextToSpeechClient()

    synthesis_input = SynthesisInput(ssml="""
<speak>
    <mark name="1"/>æ—¥æœ¬ã¸
    <mark name="2"/>å‹‰å¼·ã«
    <mark name="3"/>è¡Œãã¾ã™ã€‚
    <mark name="4"/>ã‚ãªãŸã¯
    <mark name="5"/>ã©ã“ã¸
    <mark name="6"/>è¡Œãã¾ã™ã‹ã€‚
    <mark name="7"/>ç§ã¯
    <mark name="8"/>æ—¥æœ¬ã¸
    <mark name="9"/>è¡Œãã¾ã™ã€‚
    <mark name="10"/>ã‚ãªãŸã¯
    <mark name="11"/>æ—¥æœ¬ã¸
    <mark name="12"/>ä½•ã‚’
    <mark name="13"/>ã—ã«
    <mark name="14"/>è¡Œãã¾ã™ã‹ã€‚
</speak>
""")
    voice = VoiceSelectionParams(
        language_code="ja-JP",
        name="ja-JP-Neural2-B",
        ssml_gender='FEMALE'
    )

    audio_config = AudioConfig(
        audio_encoding=AudioEncoding.MP3
    )
    request = SynthesizeSpeechRequest(
    input=synthesis_input,
    voice=voice,
    audio_config=audio_config,
    enable_time_pointing=[SynthesizeSpeechRequest.TimepointType.SSML_MARK]
    )
    response = client.synthesize_speech(request=request)

    with open("tts_output.mp3", "wb") as out:
        out.write(response.audio_content)
        print("Audio content written to file 'tts_output.mp3'")

    print("Saving to:", os.getcwd())

    timepoints = list(response.timepoints)
    print(timepoints)


if __name__ == "__main__":
    synthesize()
